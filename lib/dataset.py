import os
import glob
from PIL import Image
import random
from torch.utils.data import Dataset
import torchvision.transforms as transforms


class FaceDatasetTrain(Dataset):
    def __init__(self, dataset_root_list, isMaster, same_prob=0.2):
        self.datasets = []
        self.N = []
        self.same_prob = same_prob
 
        for dataset_root in dataset_root_list:
            imgpaths_in_root = glob.glob(f'{dataset_root}/*.*g')

            for root, dirs, _ in os.walk(dataset_root):
                for dir in dirs:
                    imgpaths_in_root += glob.glob(f'{root}/{dir}/*.*g')

            self.datasets.append(imgpaths_in_root)
            self.N.append(len(imgpaths_in_root))

        self.transforms = transforms.Compose([
            transforms.Resize((256,256)),
            transforms.RandomHorizontalFlip(p=0.5),
            transforms.ColorJitter(0.2, 0.2, 0.2, 0.01),
            transforms.ToTensor(),
            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
        ])
        if isMaster:
            print(f"Dataset of {self.__len__()} images constructed for the training.")

    def __getitem__(self, item):
        idx = 0
        while item >= self.N[idx]:
            item -= self.N[idx]
            idx += 1
        image_path = self.datasets[idx][item]
        
        Xs = Image.open(image_path).convert("RGB")

        if random.random() > self.same_prob:
            image_path = random.choice(self.datasets[random.randint(0, len(self.datasets)-1)])
            Xt = Image.open(image_path).convert("RGB")
            same_person = 0
        else:
            Xt = Xs.copy()
            same_person = 1
        return self.transforms(Xs), self.transforms(Xt), same_person

    def __len__(self):
        return sum(self.N)


class FaceDatasetValid(Dataset):
    def __init__(self, valid_data_dir, isMaster):
        
        self.source_path_list = sorted(glob.glob(f"{valid_data_dir}/source/*.*g"))
        self.target_path_list = sorted(glob.glob(f"{valid_data_dir}/target/*.*g"))

        # take the smaller number if two dirs have different numbers of images
        self.N = min(len(self.source_path_list), len(self.target_path_list))
        
        self.transforms = transforms.Compose([
            transforms.Resize((256,256)),
            transforms.ToTensor(),
            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
        ])

        if isMaster:
            print(f"Dataset of {self.__len__()} images constructed for the validation.")

    def __getitem__(self, idx):
        
        Xs = Image.open(self.source_path_list[idx]).convert("RGB")
        Xt = Image.open(self.target_path_list[idx]).convert("RGB")

        return self.transforms(Xs), self.transforms(Xt)

    def __len__(self):
        return self.N


class UnsupervisedDataset(Dataset):
    def __init__(self, dataset_root_list, scale_index=0, isMaster=False):
        self.datasets = []
        self.N = []
 
        for dataset_root in dataset_root_list:
            imgpaths_in_root = glob.glob(f'{dataset_root}/*.*g')

            for root, dirs, _ in os.walk(dataset_root):
                for dir in dirs:
                    imgpaths_in_root += glob.glob(f'{root}/{dir}/*.*g')

            self.datasets.append(imgpaths_in_root)
            self.N.append(len(imgpaths_in_root))

        size = 2**(scale_index+2)
        self.transforms = transforms.Compose([
            transforms.Resize((size, size)),
            # data augmentation
            transforms.RandomHorizontalFlip(p=0.5),
            transforms.ColorJitter(0.2, 0.2, 0.2, 0.01),
            # [0, 1]
            transforms.ToTensor(),
            # [-1, 1]
            # generator 마지막에 tanh인 경우에만 포함, sigmoid인 경우에는 생략
            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
        ])
        if isMaster:
            print(f"Dataset of {self.__len__()} images constructed for the training.")

    def __len__(self):
        return sum(self.N)

    def __getitem__(self, item):
        idx = 0
        while item >= self.N[idx]:
            item -= self.N[idx]
            idx += 1
        imgpath = self.datasets[idx][item]

        X = Image.open(imgpath).convert("RGB")
        return self.transforms(X)
